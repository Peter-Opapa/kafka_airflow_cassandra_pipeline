#!/bin/bash

# Real-Time Data Pipeline Quick Start Script
# This script helps new users get the pipeline running quickly

echo "ğŸš€ Real-Time Data Pipeline Quick Start"
echo "======================================"
echo ""

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker and try again."
    exit 1
fi

# Check if Docker Compose is available
if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Compose is not installed. Please install it and try again."
    exit 1
fi

echo "âœ… Docker is running"
echo "âœ… Docker Compose is available"
echo ""

# Check for required ports
echo "ğŸ” Checking for port conflicts..."
PORTS=(8082 9021 8083 8084 9042 5432 9092 2181)
for port in "${PORTS[@]}"; do
    if netstat -tuln 2>/dev/null | grep -q ":$port "; then
        echo "âš ï¸  Warning: Port $port is already in use"
    fi
done
echo ""

# Start the pipeline
echo "ğŸ—ï¸  Starting the Real-Time Data Pipeline..."
echo "This will download and start all required services..."
echo ""

if docker-compose up -d; then
    echo ""
    echo "âœ… All services started successfully!"
    echo ""
    echo "â³ Waiting for services to initialize (this may take 2-3 minutes)..."
    
    # Wait for services with progress indicator
    for i in {1..36}; do
        echo -n "."
        sleep 5
    done
    echo ""
    echo ""
    
    echo "ğŸ‰ Pipeline is ready!"
    echo ""
    echo "ğŸŒ Access the Web UIs:"
    echo "â”œâ”€â”€ ğŸ“Š Airflow (Pipeline Management): http://localhost:8082"
    echo "â”‚   â””â”€â”€ Username: admin | Password: yk3DNHKWbWCHnzQV"
    echo "â”œâ”€â”€ ğŸ“ˆ Kafka Control Center: http://localhost:9021"
    echo "â”œâ”€â”€ âš¡ Spark Master: http://localhost:8083"
    echo "â””â”€â”€ ğŸ”§ Spark Worker: http://localhost:8084"
    echo ""
    echo "ğŸ“‹ Useful Commands:"
    echo "â”œâ”€â”€ Check status: docker-compose ps"
    echo "â”œâ”€â”€ View logs: docker-compose logs [service-name]"
    echo "â”œâ”€â”€ Stop pipeline: docker-compose down"
    echo "â””â”€â”€ Restart: docker-compose restart"
    echo ""
    echo "ğŸ“Š Monitor Data Flow:"
    echo "â”œâ”€â”€ Kafka messages: docker exec broker kafka-console-consumer --bootstrap-server localhost:9092 --topic users_created --max-messages 5"
    echo "â””â”€â”€ Cassandra data: docker exec cassandra cqlsh -e \"SELECT COUNT(*) FROM spark_streams.created_users;\""
    echo ""
    echo "ğŸ“– For detailed documentation, see README.md and docs/WEB_UI_ACCESS.md"
    echo ""
    echo "ğŸ¯ The pipeline will start generating user data automatically!"
    echo "   Visit the Airflow UI to see the 'user_automation' DAG running."
    
else
    echo ""
    echo "âŒ Failed to start the pipeline. Please check the error messages above."
    echo ""
    echo "ğŸ”§ Troubleshooting:"
    echo "â”œâ”€â”€ Ensure Docker has enough memory allocated (8GB+ recommended)"
    echo "â”œâ”€â”€ Check for port conflicts on ports 8082, 9021, 8083, 8084"
    echo "â”œâ”€â”€ Try: docker-compose down && docker-compose up -d"
    echo "â””â”€â”€ Check logs: docker-compose logs"
    exit 1
fi
